import os
import json
import pandas as pd
from mistralai import Mistral
import time  # Pour g√©rer les pauses entre les requ√™tes
from tqdm import tqdm  # Pour afficher la barre de progression

# üîπ Cl√© API et mod√®le
api_key = "L4eMZHtfQHjV9BTwjlfiDwrzHjrT5LhG"  # Remplace par ta cl√© API
model = "mistral-large-latest"

# üîπ Cr√©e une instance du client Mistral
client = Mistral(api_key=api_key)

# üîπ Fonction pour analyser un tweet avec gestion des erreurs et respect de la limite de requ√™tes
def analyser_tweet(tweet_text):
    try:
        # Reformulation du prompt avec JSON structur√© et ajout de la r√©ponse automatique
        prompt = f"""
        Analyse le tweet suivant concernant ENGIE :
        "{tweet_text}"

        1Ô∏è‚É£ **Sentiment** (Positif, Neutre, ou N√©gatif)
        2Ô∏è‚É£ **Score d'inconfort** (0 √† 100% si N√©gatif, sinon 0)
        3Ô∏è‚É£ **Cat√©gorie** parmi :
           - Probl√®mes de facturation : erreurs de montant, pr√©l√®vements injustifi√©s.
           - Pannes et urgences : absence de gaz, d‚Äô√©lectricit√©, probl√®me d‚Äôeau chaude.
           - Service client injoignable : absence de r√©ponse, relances infructueuses.
           - Probl√®mes avec l‚Äôapplication : bugs, indisponibilit√© du service.
           - D√©lai d‚Äôintervention : retards dans la gestion des dossiers ou des r√©parations.
           - Autre

        4Ô∏è‚É£ **R√©ponse automatique** : G√©n√®re une r√©ponse pour ce client en fonction de la cat√©gorie d√©tect√©e et du probl√®me soulev√©.

        **R√©ponds uniquement avec un JSON au format strictement valide :**
        {{
            "sentiment": "Positif/Neutre/N√©gatif",
            "score_inconfort": 0-100,
            "categorie": "...",
            "reponse": "..."
        }}
        """

        # Envoi de la requ√™te en streaming
        stream_response = client.chat.stream(
            model=model,
            messages=[{"role": "user", "content": prompt}]
        )

        # R√©cup√©ration et construction de la r√©ponse
        response = ""
        for chunk in stream_response:
            response += chunk.data.choices[0].delta.content

        # Nettoyage du JSON g√©n√©r√©
        response = response.strip().replace("```json", "").replace("```", "").strip()

        # V√©rification et conversion en JSON
        try:
            response_json = json.loads(response)  # Parsing s√©curis√©
            return response_json
        except json.JSONDecodeError:
            # En cas d'erreur JSON, on retourne un r√©sultat par d√©faut
            return {"sentiment": "Erreur", "score_inconfort": 0, "categorie": "Erreur", "reponse": "Erreur"}

    except Exception as e:
        # Gestion des erreurs
        print(f"Erreur lors de l'analyse du tweet: {e}")
        return {"sentiment": "Erreur", "score_inconfort": 0, "categorie": "Erreur", "reponse": "Erreur"}

# üîπ Chargement du fichier CSV
csv_path = r"C:\Users\senth\OneDrive\Desktop\Challenge\save.csv"
df = pd.read_csv(csv_path, sep=';')

# üîπ Fusion date et heure pour cr√©er une colonne datetime
df['datetime'] = df['date'] + ' ' + df['time']
df.drop(columns=['date', 'time'], inplace=True)  # Suppression des colonnes inutiles

# üîπ Application de l'analyse sur chaque tweet de mani√®re s√©quentielle
def analyse_sequentielle(df):
    results = []
    for tweet_text in tqdm(df['text'], desc="Analyse des tweets"):
        result = analyser_tweet(tweet_text)
        results.append(result)
        time.sleep(2)  # D√©lai de 2 secondes entre chaque requ√™te pour √©viter de d√©passer la limite de l'API
    return results

# Analyse des tweets de mani√®re s√©quentielle
results = analyse_sequentielle(df)

# üîπ Ajout des r√©sultats dans le DataFrame
df['sentiment'] = [res.get('sentiment', 'Erreur') for res in results]
df['score_inconfort'] = [res.get('score_inconfort', 0) for res in results]
df['categorie'] = [res.get('categorie', 'Erreur') for res in results]
df['reponse'] = [res.get('reponse', 'Erreur') for res in results]

# üîπ Cr√©ation du format souhait√© pour chaque ligne
df['formatted'] = df.apply(lambda row: f"date : {row['datetime']} , id : {row['id']} , id_user : {row['id_user']} , text : {row['text']} , sentiment : {row['sentiment']} , score_inconfort : {row['score_inconfort']} , categorie : {row['categorie']} , reponse : {row['reponse']}", axis=1)

# üîπ Sauvegarde des r√©sultats sous forme de texte dans un fichier CSV
csv_output_path = r"C:\Users\senth\OneDrive\Desktop\Challenge\tweets_analyzes_mistral.csv"
df[['formatted']].to_csv(csv_output_path, index=False, header=False)

# üîπ Sauvegarde des r√©sultats en JSON
json_output_path = r"C:\Users\senth\OneDrive\Desktop\Challenge\tweets_analyzes_mistral.json"
df_json = df.to_dict(orient='records')  # Convertit le DataFrame en liste de dictionnaires
with open(json_output_path, 'w', encoding='utf-8') as json_file:
    json.dump(df_json, json_file, ensure_ascii=False, indent=4)

print("\n‚úÖ Analyse termin√©e ! R√©sultats enregistr√©s dans :", csv_output_path)
print("\nüìä Aper√ßu des r√©sultats :")
print(df[['formatted']].head())  # Affiche un aper√ßu des r√©sultats format√©s
